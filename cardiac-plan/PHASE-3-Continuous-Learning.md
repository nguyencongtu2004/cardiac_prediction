
## ðŸŽ¯ PHASE 3: CONTINUOUS LEARNING (Tuáº§n 2)

### Má»¥c tiÃªu Phase 3
- Implement feedback loop tá»« predictions vá» training
- Enable incremental learning tá»« streaming data
- Auto-retrain khi cÃ³ Ä‘á»§ labeled data

---

### BÆ¯á»šC 3.1: Database Schema cho Feedback Loop (2 giá»)

#### Nhiá»‡m vá»¥ chÃ­nh:

1. **Thiáº¿t káº¿ báº£ng `cardiac_ground_truth`**
   - **Columns cáº§n cÃ³**:
     - id (primary key)
     - patient_id (foreign key liÃªn káº¿t vá»›i predictions)
     - prediction_time (timestamp cá»§a prediction gá»‘c)
     - predicted_label (0 hoáº·c 1)
     - risk_probability (probability tá»« model)
     - actual_outcome (NULL cho Ä‘áº¿n khi Ä‘Æ°á»£c gáº¯n nhÃ£n)
     - labeled_at (timestamp khi doctor gáº¯n nhÃ£n)
     - labeled_by (username cá»§a doctor)
     - notes (optional, ghi chÃº thÃªm)

2. **Create indexes**
   - Index trÃªn patient_id (tra cá»©u nhanh)
   - Index trÃªn prediction_time (sort by time)
   - Index trÃªn actual_outcome IS NULL (query unlabeled records)

3. **Add vÃ o init_database.sql**
   - SQL script táº¡o báº£ng
   - SQL script táº¡o indexes
   - Test script trong Docker container

#### Output:
- Updated `init_database.sql`
- Database schema document
- Verification: Báº£ng táº¡o thÃ nh cÃ´ng trong PostgreSQL

---

### BÆ¯á»šC 3.2: Streamlit Feedback UI (4 giá»)

#### Nhiá»‡m vá»¥ chÃ­nh:

1. **Design feedback interface**
   - **New page**: "Doctor Feedback - Label Predictions"
   - **Features**:
     - List unlabeled predictions (top 20 by risk probability)
     - Show patient info + predicted risk
     - Dropdown Ä‘á»ƒ select actual outcome:
       - "Not Yet Known"
       - "Patient Admitted (High Risk Confirmed)"
       - "Patient Not Admitted (False Alarm)"
     - Text area cho notes
     - Submit button

2. **Implement query logic**
   - Query PostgreSQL Ä‘á»ƒ láº¥y predictions chÆ°a cÃ³ ground truth
   - Join giá»¯a `cardiac_predictions` vÃ  `cardiac_ground_truth`
   - Filter: WHERE actual_outcome IS NULL
   - Order by risk_probability DESC

3. **Implement submission logic**
   - On submit button click:
     - Insert record vÃ o `cardiac_ground_truth`
     - Update labeled_at = NOW()
     - Update labeled_by = current user
     - Show success message
     - Refresh page

4. **Add user authentication (optional)**
   - Simple username input
   - Hoáº·c integrate vá»›i LDAP/SSO náº¿u cÃ³

#### Output:
- Updated `streamlit_app.py` vá»›i feedback page
- Test: Doctor cÃ³ thá»ƒ gáº¯n nhÃ£n predictions thÃ nh cÃ´ng
- Screenshots cá»§a feedback UI

---

### BÆ¯á»šC 3.3: Feedback Data Collection Strategy (2 giá»)

#### Nhiá»‡m vá»¥ chÃ­nh:

1. **Define labeling workflow**
   - **Ai gáº¯n nhÃ£n?**: Doctors, nurses, hoáº·c tá»« EMR system
   - **Khi nÃ o gáº¯n nhÃ£n?**: 
     - Option 1: Sau 24-48 giá» (khi outcome rÃµ rÃ ng)
     - Option 2: Äá»‹nh ká»³ review batch predictions
   - **TiÃªu chÃ­ gáº¯n nhÃ£n**: Patient admitted within 7 days = high risk confirmed

2. **Simulate feedback data (for testing)**
   - Script Ä‘á»ƒ tá»± Ä‘á»™ng gáº¯n nhÃ£n test data
   - Random sampling vá»›i realistic distribution
   - Insert vÃ o `cardiac_ground_truth`

3. **Monitor feedback data quality**
   - Track % predictions Ä‘Æ°á»£c gáº¯n nhÃ£n
   - Track label distribution (high risk vs normal)
   - Alert náº¿u labeling rate quÃ¡ tháº¥p

#### Output:
- Labeling workflow document
- Script simulate feedback data
- Monitoring query scripts

---

### BÆ¯á»šC 3.4: Merge Feedback Data Script (4 giá»)

#### Nhiá»‡m vá»¥ chÃ­nh:

1. **Design data merging strategy**
   - **Input sources**:
     - Historical training data (parquet files)
     - New feedback data (tá»« PostgreSQL)
   - **Merging approach**:
     - Union hai datasets
     - Apply weighting: feedback data cÃ³ weight cao hÆ¡n (vd: 3x)
     - Reason: Feedback data gáº§n vá»›i distribution hiá»‡n táº¡i hÆ¡n

2. **Implement merge script**
   - File: `merge_feedback_retrain.py`
   - **Steps**:
     1. Load feedback data tá»« PostgreSQL (JDBC)
     2. Transform sang Spark DataFrame
     3. Load historical training data
     4. Add weight column (1.0 vs 3.0)
     5. Union datasets
     6. Save merged dataset (parquet)

3. **Handle data quality**
   - Remove duplicates (same patient_id + prediction_time)
   - Validate data schema
   - Check for missing values
   - Log data statistics

#### Output:
- Script `merge_feedback_retrain.py`
- Test: Merge thÃ nh cÃ´ng vá»›i simulated feedback data
- Merged dataset statistics report

---

### BÆ¯á»šC 3.5: Incremental Retraining Logic (5 giá»)

#### Nhiá»‡m vá»¥ chÃ­nh:

1. **Design retraining strategy**
   - **Trigger conditions**:
     - Option 1: Time-based (weekly)
     - Option 2: Data-based (khi cÃ³ 1000+ new labels)
     - Option 3: Drift-based (khi detect concept drift)
   - **Recommend**: Káº¿t há»£p time-based + data-based

2. **Implement retraining pipeline**
   - Load merged dataset (historical + feedback)
   - Apply same feature engineering pipeline
   - Apply same model training pipeline (vá»›i hyperparameters Ä‘Ã£ tune)
   - Evaluate trÃªn fresh test set (tá»« feedback data gáº§n nháº¥t)

3. **Model comparison logic**
   - Compare new model vs current production model
   - **Metrics to compare**:
     - AUC-ROC
     - F1 score
     - Recall (critical cho medical use case)
   - **Promotion criteria**:
     - AUC improvement > 0.01 AND
     - Recall khÃ´ng giáº£m > 2%

4. **Implement trong `merge_feedback_retrain.py`**
   - Reuse training logic tá»« `cardiac_model_train_v2.py`
   - Add comparison vÃ  promotion logic
   - Save new model vá»›i version number

#### Output:
- Incremental retraining logic implemented
- Model promotion criteria documented
- Test: Retrain thÃ nh cÃ´ng vá»›i merged data

---

### BÆ¯á»šC 3.6: Incremental Retraining DAG (3 giá»)

#### Nhiá»‡m vá»¥ chÃ­nh:

1. **Create new DAG: `cardiac_incremental_retrain_dag.py`**
   - **Schedule**: @weekly hoáº·c manual trigger
   - **Tasks**:
     1. check_feedback_availability (Python sensor)
     2. merge_feedback_data (Bash: spark-submit)
     3. retrain_model (Bash: spark-submit)
     4. evaluate_new_model (Python)
     5. compare_and_promote (Python)
     6. update_production_model (Bash: copy files)

2. **Implement sensor task**
   - Check PostgreSQL:
     - Count records WHERE labeled_at > NOW() - INTERVAL '7 days'
   - If count < threshold (vd: 50), skip DAG run
   - Else, proceed with retraining

3. **Add monitoring vÃ  alerting**
   - Send email khi retrain starts
   - Send email khi new model promoted
   - Send alert náº¿u retrain fails

4. **Test DAG execution**
   - Trigger manually
   - Verify tá»«ng task cháº¡y thÃ nh cÃ´ng
   - Check model files updated

#### Output:
- DAG file `cardiac_incremental_retrain_dag.py`
- DAG visible trong Airflow UI
- Test execution successful

---

### BÆ¯á»šC 3.7: Continuous Learning Validation (3 giá»)

#### Nhiá»‡m vá»¥ chÃ­nh:

1. **Simulate continuous learning cycle**
   - **Day 0**: Train baseline model
   - **Day 1-7**: Generate predictions
   - **Day 7**: Doctor gáº¯n nhÃ£n batch 1 (100 predictions)
   - **Day 8**: Trigger incremental retrain â†’ Model v2
   - **Day 8-14**: Generate predictions vá»›i Model v2
   - **Day 14**: Doctor gáº¯n nhÃ£n batch 2 (100 predictions)
   - **Day 15**: Trigger incremental retrain â†’ Model v3

2. **Track model improvement**
   - Plot AUC over model versions (v1 â†’ v2 â†’ v3)
   - Expect to see improvement hoáº·c stability
   - Document insights

3. **Validate feedback loop hoÃ n chá»‰nh**
   - End-to-end test: prediction â†’ feedback â†’ retrain â†’ deploy â†’ predict again
   - Check khÃ´ng cÃ³ data leakage
   - Verify model versions tracked correctly

#### Output:
- Simulation test report
- Model improvement chart
- Validation: âœ… Continuous learning working
