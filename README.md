# ğŸš€ Big Data Streaming ABSA with Automated Model Retraining

> **Há»‡ thá»‘ng ABSA (Aspect-Based Sentiment Analysis) vá»›i kháº£ nÄƒng streaming real-time vÃ  tá»± Ä‘á»™ng huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh**

## ğŸ“– Tá»•ng quan

Há»‡ thá»‘ng Big Data hoÃ n chá»‰nh káº¿t há»£p:

- âœ… **Kafka + Spark Structured Streaming**: Xá»­ lÃ½ dá»¯ liá»‡u real-time
- âœ… **Deep Learning ABSA**: PhÃ¢n tÃ­ch cáº£m xÃºc Ä‘a khÃ­a cáº¡nh
- âœ… **Automated ML Pipeline**: Tá»± Ä‘á»™ng huáº¥n luyá»‡n & cáº­p nháº­t mÃ´ hÃ¬nh
- âœ… **Model Registry**: Quáº£n lÃ½ phiÃªn báº£n mÃ´ hÃ¬nh
- âœ… **Auto-reload Model**: Consumer tá»± Ä‘á»™ng táº£i mÃ´ hÃ¬nh má»›i
- âœ… **Streamlit Dashboard**: Hiá»ƒn thá»‹ káº¿t quáº£ real-time

---

## ğŸ¯ TÃ­nh nÄƒng chÃ­nh

### 1ï¸âƒ£ **Streaming Pipeline** (cháº¡y má»—i giá»)

- Producer Ä‘á»c CSV â†’ gá»­i Kafka
- Consumer (v2) nháº­n Kafka â†’ Inference ABSA â†’ PostgreSQL
- **Tá»± Ä‘á»™ng reload mÃ´ hÃ¬nh** khi cÃ³ model má»›i Ä‘Æ°á»£c promote

### 2ï¸âƒ£ **Retraining Pipeline** (cháº¡y Chá»§ nháº­t 2:00 AM)

- Load dá»¯ liá»‡u má»›i tá»« PostgreSQL
- Train mÃ´ hÃ¬nh ABSA má»›i (XLM-RoBERTa)
- **ÄÃ¡nh giÃ¡ & so sÃ¡nh** vá»›i mÃ´ hÃ¬nh production
- **Chá»‰ promote náº¿u tá»‘t hÆ¡n** (improvement > 1%)

### 3ï¸âƒ£ **Model Registry**

- LÆ°u trá»¯ metadata cá»§a táº¥t cáº£ mÃ´ hÃ¬nh
- Theo dÃµi metrics (F1, accuracy, overall score)
- Quáº£n lÃ½ production model
- Backup tá»± Ä‘á»™ng

---

## ğŸ“ Cáº¥u trÃºc há»‡ thá»‘ng

**Cáº¥u trÃºc gá»‘c (root `C:\airflow`) â€” tÃ³m táº¯t nhanh**

- `docker-compose.yaml`
  Äá»‹nh nghÄ©a toÃ n bá»™ stack (Airflow, Kafka, Zookeeper, Spark, PostgreSQL, v.v.) dÃ¹ng Ä‘á»ƒ khá»Ÿi Ä‘á»™ng báº±ng Docker Compose.
- `.env`
  Biáº¿n mÃ´i trÆ°á»ng cáº¥u hÃ¬nh chung (UID, ports, credential, â€¦).

**ThÆ° má»¥c chÃ­nh vÃ  chá»©c nÄƒng**

- `dags/`
  Chá»©a cÃ¡c file DAG (.py). Airflow Scheduler quÃ©t /opt/airflow/dags (mount tá»« mÃ¡y host) Ä‘á»ƒ load workflow. (Äáº·t DAG vÃ o Ä‘Ã¢y Ä‘á»ƒ Airflow tá»± nháº­n.)
- `logs/`
  LÆ°u log cá»§a cÃ¡c task/DAG cháº¡y trong Airflow.
- `plugins/`
  Chá»©a plugin tuá»³ biáº¿n cho Airflow (operator/custom hooks/â€¦).
- `config/`
  Cáº¥u hÃ¬nh tuá»³ chá»‰nh (náº¿u cÃ³) cho Airflow hoáº·c project (vÃ­ dá»¥ config cho Spark, Kafka, connection strings).
- `base/`
  DÃ¹ng Ä‘á»ƒ build image base `airflow-base`: cÃ³ `Dockerfile` vÃ  `requirements.txt` chá»©a cÃ¡c lib náº·ng (Java, pyspark, torch, kafka-client, transformers, â€¦). Má»¥c Ä‘Ã­ch: chung hÃ³a mÃ´i trÆ°á»ng, giáº£m thá»i gian build cho má»i project con.

  - `base/Dockerfile` â€” cÃ i Java, cÃ i Python libs, xÃ¢y image tá»« `apache/airflow:2.9.0`.
  - `base/requirements.txt` â€” list thÆ° viá»‡n chung (pyspark, kafka-python, torch, pandas, streamlit, â€¦).

- `models/`
  Chá»©a file trá»ng sá»‘ mÃ´ hÃ¬nh (vÃ­ dá»¥ `absa_model.pt`) dÃ¹ng bá»Ÿi job inference.
- `projects/`
  Chá»©a cÃ¡c project con (vÃ­ dá»¥ `absa_streaming/`). Má»—i project cÃ³ folder riÃªng gá»“m mÃ£ nguá»“n, script, data, webapp.

  - `projects/absa_streaming/scripts/` â€” producer.py, consumer_postgres_streaming.py, script cháº¡y Spark/producer/consumer.
  - `projects/absa_streaming/data/` â€” dá»¯ liá»‡u máº«u (CSV, test data).
  - `projects/absa_streaming/streamlit/` â€” mÃ£ Streamlit dashboard hiá»ƒn thá»‹ káº¿t quáº£ realtime.
  - `projects/absa_streaming/requirements.txt` (tuá»³ chá»n) â€” lib riÃªng cho project.
  - `projects/absa_streaming/README.md` â€” mÃ´ táº£ ngáº¯n project.

- `checkpoints/` (Ä‘Æ°á»£c Ä‘á» cáº­p)
  ThÆ° má»¥c nÆ¡i Spark lÆ°u checkpoint; Airflow cÃ³ task monitor/cleanup Ä‘á»ƒ kiá»ƒm tra vÃ  xÃ³a checkpoint theo lifecycle.

**CÃ¡c DAG & pipeline chÃ­nh Ä‘Æ°á»£c mÃ´ táº£**

- `absa_streaming_lifecycle` (vÃ­ dá»¥ DAG) â€” orchestration Kafka â†’ Spark â†’ PostgreSQL:

  - `deploy_producer` (BashOperator) â€” cháº¡y producer Ä‘á»ƒ push CSV â†’ Kafka.
  - `deploy_consumer` (SparkSubmitOperator / BashOperator) â€” cháº¡y Spark Structured Streaming, inference model `.pt`, ghi káº¿t quáº£ vÃ o PostgreSQL.
  - `monitor_stream` (PythonOperator) â€” kiá»ƒm tra checkpoint/kafka lag/postgres writes, gá»­i cáº£nh bÃ¡o.
  - `cleanup_checkpoints` (BashOperator) â€” xÃ³a checkpoint cÅ© sau vÃ²ng cháº¡y.

- Thiáº¿t láº­p `schedule_interval`, `execution_timeout`, `dagrun_timeout`, `retries`, `retry_delay` Ä‘á»ƒ control lifecycle (vÃ­ dá»¥: daily DAG, dagrun_timeout â‰ˆ 23.8h).

---

## ğŸš€ Quick Start

### **Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng:**

```powershell
# 1. Set environment
$env:AIRFLOW_UID = "50000"

# 2. Build vÃ  khá»Ÿi Ä‘á»™ng
docker-compose build
docker-compose up airflow-init
docker-compose up -d

# 3. Khá»Ÿi táº¡o database schema
docker cp config/init_database.sql $(docker ps -qf "name=postgres"):/tmp/
docker exec -i $(docker ps -qf "name=postgres") psql -U airflow -d airflow -f /tmp/init_database.sql

# 4. Truy cáº­p UIs
# Airflow: http://localhost:8080 (airflow/airflow)
# Streamlit: http://localhost:8501
```

### **Sá»­ dá»¥ng Management Scripts:**

```powershell
# Import module
. .\scripts\management.ps1

# Khá»Ÿi Ä‘á»™ng stack
Start-ABSAStack

# Kiá»ƒm tra tráº¡ng thÃ¡i
Get-ABSAStatus

# Trigger DAG
Start-RetrainingDAG

# Xem logs
Get-TrainingLogs

# Xem káº¿t quáº£
Get-ABSAResults -Limit 20
```

---

## ğŸ“Š DAGs cÃ³ sáºµn

### 1. **`absa_streaming_lifecycle_v2`** (Má»—i giá»)

Pipeline streaming chÃ­nh vá»›i auto-reload model:

- âœ… Deploy Producer (Kafka)
- âœ… Deploy Consumer v2 (Spark + Auto-reload)
- âœ… Monitor checkpoint & model
- âœ… Cleanup

### 2. **`absa_model_retraining`** (Chá»§ nháº­t 2:00 AM)

Pipeline huáº¥n luyá»‡n tá»± Ä‘á»™ng:

- âœ… Prepare training data
- âœ… Train new model
- âœ… Evaluate & compare
- âœ… Promote if better (>1% improvement)
- âœ… Cleanup old models

---

## ğŸ”§ TÃ¹y chá»‰nh

### **Thay Ä‘á»•i lá»‹ch retraining:**

File: `dags/absa_model_retraining_dag.py`

```python
# Cháº¡y hÃ ng ngÃ y lÃºc 3:00 AM
schedule_interval="0 3 * * *"
```

### **Äiá»u chá»‰nh ngÆ°á»¡ng promote:**

File: `projects/absa_streaming/training/evaluate_and_promote.py`

```python
IMPROVEMENT_THRESHOLD = 0.02  # 2% thay vÃ¬ 1%
```

### **Tham sá»‘ training:**

File: `projects/absa_streaming/training/train_absa_model.py`

```python
EPOCHS = 5
BATCH_SIZE = 32
LEARNING_RATE = 1e-5
```

---

## ğŸ“ˆ Monitoring

### **Kiá»ƒm tra mÃ´ hÃ¬nh production:**

```sql
-- Trong PostgreSQL
SELECT * FROM model_performance_summary;
```

### **Xem lá»‹ch sá»­ training:**

```powershell
docker exec $(docker ps -qf "name=airflow-scheduler") cat /opt/airflow/projects/absa_streaming/training/evaluation_log.json
```

### **Theo dÃµi streaming:**

```powershell
# Logs consumer
docker logs -f $(docker ps -qf "name=airflow-scheduler")

# Káº¿t quáº£ trong database
docker exec -i $(docker ps -qf "name=postgres") psql -U airflow -d airflow -c "SELECT COUNT(*) FROM absa_results;"
```

---

## ğŸ†• Äiá»ƒm má»›i so vá»›i phiÃªn báº£n cÅ©

| Feature          | Old Version  | **New Version**               |
| ---------------- | ------------ | ----------------------------- |
| Consumer         | Static model | âœ… **Auto-reload model**      |
| Model update     | Manual copy  | âœ… **Automated pipeline**     |
| Model evaluation | None         | âœ… **Auto compare & promote** |
| Model registry   | None         | âœ… **PostgreSQL tracking**    |
| Retraining       | Manual       | âœ… **Scheduled (weekly)**     |
| Backup           | None         | âœ… **Auto backup old models** |

---

## ğŸ“š TÃ i liá»‡u chi tiáº¿t

ğŸ‘‰ **Xem hÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§ táº¡i: [DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md)**

Bao gá»“m:

- Kiáº¿n trÃºc há»‡ thá»‘ng chi tiáº¿t
- Workflow Ä‘áº§y Ä‘á»§
- Database schema
- Troubleshooting
- Best practices

---

## ğŸ§ª Testing

### **Test streaming:**

```powershell
# Trigger manual
Start-StreamingDAG

# Hoáº·c trong Airflow UI
# DAGs â†’ absa_streaming_lifecycle_v2 â†’ Trigger
```

### **Test retraining:**

```powershell
# Trigger manual
Start-RetrainingDAG

# Kiá»ƒm tra káº¿t quáº£
Get-TrainingLogs
Get-ModelRegistry
```

---

## ğŸ” Troubleshooting

### **Consumer khÃ´ng reload model:**

```powershell
# Kiá»ƒm tra timestamp
docker exec $(docker ps -qf "name=airflow-scheduler") ls -lh /opt/airflow/models/

# Clear checkpoint vÃ  restart
Clear-Checkpoints
Start-StreamingDAG
```

### **Training fails:**

```powershell
# Xem logs chi tiáº¿t
Get-TrainingLogs

# Giáº£m batch size náº¿u OOM
# Edit: projects/absa_streaming/training/train_absa_model.py
# BATCH_SIZE = 8
```

---

## ğŸ“ LÆ°u Ã½ quan trá»ng

**Äiá»ƒm cáº§n chÃº Ã½ khi triá»ƒn khai:**

- âœ… DÃ¹ng `airflow-base` image Ä‘á»ƒ trÃ¡nh cÃ i láº¡i lib náº·ng
- âœ… Consumer v2 tá»± Ä‘á»™ng reload model - khÃ´ng cáº§n restart
- âœ… MÃ´ hÃ¬nh chá»‰ Ä‘Æ°á»£c promote náº¿u **tá»‘t hÆ¡n > 1%**
- âœ… Mount chÃ­nh xÃ¡c `dags/` vÃ  `models/` vÃ o container
- âœ… Quáº£n lÃ½ checkpoint Spark cáº©n tháº­n
- âœ… Cáº¥u hÃ¬nh retry/timeout há»£p lÃ½ cho streaming job

---

## ğŸ‘¥ ThÃ´ng tin

**SE363 â€“ PhÃ¡t triá»ƒn á»©ng dá»¥ng trÃªn ná»n táº£ng dá»¯ liá»‡u lá»›n**  
Khoa CÃ´ng nghá»‡ Pháº§n má»m  
TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin, ÄHQG-HCM

---

**ğŸ‰ Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng! ChÃºc báº¡n thÃ nh cÃ´ng!**
