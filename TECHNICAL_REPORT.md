# BÃO CÃO Ká»¸ THUáº¬T CHI TIáº¾T

## Há»‡ Thá»‘ng PhÃ¡t Hiá»‡n Vi Pháº¡m Giao ThÃ´ng Thá»i Gian Thá»±c

---

## Má»¤C Lá»¤C

1. [Tá»•ng Quan Dá»± Ãn](#1-tá»•ng-quan-dá»±-Ã¡n)
2. [Kiáº¿n TrÃºc Há»‡ Thá»‘ng](#2-kiáº¿n-trÃºc-há»‡-thá»‘ng)
3. [CÃ¡c ThÃ nh Pháº§n Chi Tiáº¿t](#3-cÃ¡c-thÃ nh-pháº§n-chi-tiáº¿t)
4. [Thuáº­t ToÃ¡n PhÃ¡t Hiá»‡n Vi Pháº¡m](#4-thuáº­t-toÃ¡n-phÃ¡t-hiá»‡n-vi-pháº¡m)
5. [Object Tracking](#5-object-tracking)
6. [Data Pipeline](#6-data-pipeline)
7. [CÆ¡ Sá»Ÿ Dá»¯ Liá»‡u](#7-cÆ¡-sá»Ÿ-dá»¯-liá»‡u)
8. [Cáº¥u HÃ¬nh ROI](#8-cáº¥u-hÃ¬nh-roi)
9. [Web Application](#9-web-application)
10. [Hiá»‡u Suáº¥t vÃ  ÄÃ¡nh GiÃ¡](#10-hiá»‡u-suáº¥t-vÃ -Ä‘Ã¡nh-giÃ¡)
11. [Háº¡n Cháº¿ vÃ  HÆ°á»›ng PhÃ¡t Triá»ƒn](#11-háº¡n-cháº¿-vÃ -hÆ°á»›ng-phÃ¡t-triá»ƒn)

---

## 1. Tá»•ng Quan Dá»± Ãn

### 1.1 Má»¥c TiÃªu

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  giÃ¡m sÃ¡t vi pháº¡m giao thÃ´ng **thá»i gian thá»±c** tá»« camera giÃ¡m sÃ¡t, sá»­ dá»¥ng cÃ¡c cÃ´ng nghá»‡ hiá»‡n Ä‘áº¡i bao gá»“m:

- **AI/ML**: YOLOv8 (Ultralytics) cho object detection
- **Message Queue**: Apache Kafka cho xá»­ lÃ½ stream
- **Orchestration**: Apache Airflow cho quáº£n lÃ½ pipeline
- **Database**: PostgreSQL cho lÆ°u trá»¯ dá»¯ liá»‡u
- **Backend**: FastAPI vá»›i WebSocket
- **Frontend**: Next.js vá»›i real-time updates

### 1.2 CÃ¡c Loáº¡i Vi Pháº¡m ÄÆ°á»£c PhÃ¡t Hiá»‡n

| Vi Pháº¡m                   | Model                 | PhÆ°Æ¡ng PhÃ¡p                                 |
| ------------------------- | --------------------- | ------------------------------------------- |
| **KhÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm** | `best.pt` (8 classes) | Person + Motorcycle + No Helmet detection   |
| **VÆ°á»£t Ä‘Ã¨n Ä‘á»**           | `yolov8n.pt`          | Vehicle crosses stop line when light is RED |
| **Láº¥n lÃ n**               | `yolov8n.pt`          | Vehicle crosses solid lane line             |

### 1.3 Cáº¥u TrÃºc ThÆ° Má»¥c Dá»± Ãn

```
cardiac_prediction/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ backend/                    # FastAPI backend service
â”‚   â”‚   â”œâ”€â”€ main.py                 # WebSocket + REST API (787 lines)
â”‚   â”‚   â”œâ”€â”€ config.py               # Centralized configuration
â”‚   â”‚   â”œâ”€â”€ services/               # Business logic modules
â”‚   â”‚   â””â”€â”€ routers/                # API route handlers
â”‚   â””â”€â”€ frontend/                    # Next.js frontend application
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ app/                # Pages & routing
â”‚           â””â”€â”€ components/         # UI components
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ detectors/                   # Shared detection logic
â”‚   â”‚   â”œâ”€â”€ base.py                 # Utilities (203 lines)
â”‚   â”‚   â”œâ”€â”€ tracker.py              # CentroidTracker (104 lines)
â”‚   â”‚   â”œâ”€â”€ redlight_detector.py    # Red light logic (299 lines)
â”‚   â”‚   â”œâ”€â”€ helmet_detector.py      # Helmet logic (538 lines)
â”‚   â”‚   â””â”€â”€ lane_detector.py        # Lane logic (339 lines)
â”‚   â”œâ”€â”€ producers/                   # Kafka producers
â”‚   â”‚   â”œâ”€â”€ kafka_producer.py       # Camera feed ingestion
â”‚   â”‚   â””â”€â”€ video_producer.py       # Multi-video streaming (224 lines)
â”‚   â””â”€â”€ consumers/                   # Kafka consumers
â”‚       â”œâ”€â”€ db_consumer.py          # PostgreSQL writer
â”‚       â”œâ”€â”€ helmet_detector_consumer.py
â”‚       â”œâ”€â”€ redlight_detector_consumer.py
â”‚       â””â”€â”€ lane_detector_consumer.py
â”œâ”€â”€ scripts/                         # Standalone detection scripts
â”‚   â”œâ”€â”€ detect_helmet_violation.py
â”‚   â”œâ”€â”€ detect_redlight_violation.py
â”‚   â”œâ”€â”€ detect_lane_violation.py
â”‚   â””â”€â”€ configure_roi.py            # ROI configuration tool
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                        # Airflow DAGs
â”‚   â””â”€â”€ config/                      # Database init scripts
â”œâ”€â”€ config/
â”‚   â””â”€â”€ roi_config.json              # Camera ROI configurations
â”œâ”€â”€ models/                          # YOLO model files
â”‚   â”œâ”€â”€ best.pt                     # Unified helmet model (8 classes)
â”‚   â””â”€â”€ yolov8n.pt                  # General object detection
â””â”€â”€ docker-compose.yaml              # Full stack orchestration
```

---

## 2. Kiáº¿n TrÃºc Há»‡ Thá»‘ng

### 2.1 SÆ¡ Äá»“ Kiáº¿n TrÃºc Tá»•ng Quan

```mermaid
flowchart TB
    subgraph "Data Sources"
        CAM[ğŸ¥ Traffic Cameras<br/>HCM City API]
        VID[ğŸ“¹ Video Files<br/>/data/video/]
    end

    subgraph "Data Ingestion"
        PROD[Kafka Producer<br/>video_producer.py]
        K1[(Kafka Topic<br/>helmet_video_frames)]
    end

    subgraph "Stream Processing"
        HC[Helmet Consumer<br/>helmet_detector_consumer.py]
        RC[RedLight Consumer<br/>redlight_detector_consumer.py]
        LC[Lane Consumer<br/>lane_detector_consumer.py]
    end

    subgraph "Detection Logic"
        HD[Helmet Detector<br/>best.pt - 8 classes]
        RD[RedLight Detector<br/>yolov8n.pt + HSV]
        LD[Lane Detector<br/>yolov8n.pt + Geometry]
    end

    subgraph "Output Topics"
        K2[(helmet_violations)]
        K3[(redlight_violations)]
        K4[(lane_violations)]
    end

    subgraph "Persistence & API"
        DB[(PostgreSQL<br/>traffic_monitoring)]
        BE[FastAPI Backend<br/>:8000]
        WS[WebSocket<br/>/ws]
    end

    subgraph "Frontend"
        FE[Next.js Dashboard<br/>:3002]
    end

    CAM --> PROD
    VID --> PROD
    PROD --> K1

    K1 --> HC --> HD --> K2
    K1 --> RC --> RD --> K3
    K1 --> LC --> LD --> K4

    K2 --> BE
    K3 --> BE
    K4 --> BE

    BE --> DB
    BE --> WS --> FE

    style HD fill:#ffe0e5
    style RD fill:#fff3e0
    style LD fill:#e1f5ff
    style DB fill:#e8f5e9
```

### 2.2 Docker Services

Há»‡ thá»‘ng Ä‘Æ°á»£c container hÃ³a hoÃ n toÃ n vá»›i cÃ¡c services:

| Service             | Image                       | Port | Chá»©c NÄƒng          |
| ------------------- | --------------------------- | ---- | ------------------ |
| `postgres`          | postgres:13                 | 5432 | Database chÃ­nh     |
| `redis`             | redis:8.2.2                 | 6379 | Celery broker      |
| `kafka`             | confluentinc/cp-kafka:7.5.0 | 9092 | Message queue      |
| `zookeeper`         | zookeeper:3.8               | 2181 | Kafka coordination |
| `airflow-webserver` | custom:2.9.0                | 8080 | Airflow UI         |
| `airflow-scheduler` | custom:2.9.0                | -    | Task scheduling    |
| `airflow-worker`    | custom:2.9.0                | -    | Task execution     |
| `traffic-backend`   | custom                      | 8000 | FastAPI backend    |
| `traffic-frontend`  | custom                      | 3002 | Next.js frontend   |

---

## 3. CÃ¡c ThÃ nh Pháº§n Chi Tiáº¿t

### 3.1 Base Utilities (`pipeline/detectors/base.py`)

Module nÃ y cung cáº¥p cÃ¡c utility functions dÃ¹ng chung cho táº¥t cáº£ detectors:

#### 3.1.1 Box Utilities

```python
def clamp_box(box: List[int], W: int, H: int) -> List[int]:
    """Giá»›i háº¡n box [x, y, w, h] trong ranh giá»›i áº£nh"""

def box_xyxy(box: List[int]) -> Tuple[int, int, int, int]:
    """Chuyá»ƒn [x, y, w, h] sang (x1, y1, x2, y2)"""

def centroid(box: List[int]) -> Tuple[float, float]:
    """Láº¥y tÃ¢m Ä‘iá»ƒm cá»§a box"""

def bottom_center(box: List[int]) -> Tuple[float, float]:
    """Láº¥y Ä‘iá»ƒm giá»¯a Ä‘Ã¡y box (dÃ¹ng cho stop line crossing)"""

def iou(a: List[int], b: List[int]) -> float:
    """TÃ­nh Intersection over Union giá»¯a 2 boxes"""

def point_in_polygon(point, polygon) -> bool:
    """Ray casting algorithm Ä‘á»ƒ kiá»ƒm tra Ä‘iá»ƒm trong polygon"""
```

#### 3.1.2 Drawing Utilities

```python
def draw_box(img, box, label, color, thickness)
def draw_stop_line(img, y_pos, color, thickness)
def draw_detection_zone(img, zone, color, thickness)
```

#### 3.1.3 Config Utilities

```python
def load_roi_config(config_path) -> Dict:
    """Load ROI config tá»« JSON file"""

def get_camera_config(all_config, camera_id) -> Dict:
    """Láº¥y config theo camera vá»›i fallback vá» default"""

def scale_config(config, actual_width, actual_height) -> Dict:
    """Scale ROI config theo kÃ­ch thÆ°á»›c frame thá»±c táº¿"""
```

> **Äiá»ƒm quan trá»ng**: HÃ m `scale_config()` cho phÃ©p cáº¥u hÃ¬nh ROI á»Ÿ kÃ­ch thÆ°á»›c chuáº©n (1920x1080) vÃ  tá»± Ä‘á»™ng scale theo resolution thá»±c táº¿ cá»§a video/camera.

### 3.2 Video Producer (`pipeline/producers/video_producer.py`)

Producer há»— trá»£ streaming nhiá»u video song song:

```python
# Cáº¥u hÃ¬nh
KAFKA_TOPIC = 'helmet_video_frames'
TARGET_FPS = 15  # FPS má»¥c tiÃªu
LOOP_VIDEO = False  # CÃ³ láº·p video khÃ´ng

# Message format gá»­i Ä‘áº¿n Kafka
message = {
    "camera_id": camera_id,
    "frame_number": frame_count,
    "timestamp": datetime.now().isoformat(),
    "image_base64": base64_encoded_frame,
    "width": frame.shape[1],
    "height": frame.shape[0]
}
```

**Äáº·c Ä‘iá»ƒm**:

- Há»— trá»£ multi-threading cho nhiá»u video Ä‘á»“ng thá»i
- Tá»± Ä‘á»™ng resize frame > 720p Ä‘á»ƒ tiáº¿t kiá»‡m bandwidth
- Compression vá»›i GZIP
- Frame skip Ä‘á»ƒ Ä‘áº¡t target FPS

---

## 4. Thuáº­t ToÃ¡n PhÃ¡t Hiá»‡n Vi Pháº¡m

### 4.1 PhÃ¡t Hiá»‡n KhÃ´ng Äá»™i MÅ© Báº£o Hiá»ƒm (`helmet_detector.py`)

#### 4.1.1 Model Architecture

Sá»­ dá»¥ng **Unified Model** (`best.pt`) vá»›i 8 classes:

| Class ID | Class Name     | MÃ´ táº£              |
| -------- | -------------- | ------------------ |
| 0        | person         | NgÆ°á»i              |
| 1        | bicycle        | Xe Ä‘áº¡p             |
| 2        | car            | Ã” tÃ´               |
| 3        | motorcycle     | Xe mÃ¡y             |
| 4        | bus            | Xe buÃ½t            |
| 5        | truck          | Xe táº£i             |
| 6        | with_helmet    | NgÆ°á»i Ä‘á»™i mÅ©       |
| 7        | without_helmet | NgÆ°á»i khÃ´ng Ä‘á»™i mÅ© |

#### 4.1.2 Detection Strategy

```mermaid
flowchart TD
    A[Frame Input] --> B[YOLO Inference<br/>best.pt]
    B --> C{Detect Objects}

    C --> D[persons boxes]
    C --> E[vehicles boxes<br/>motorcycle, bicycle]
    C --> F[with_helmet boxes]
    C --> G[without_helmet boxes]

    subgraph "Strategy 1: Direct Detection"
        G --> H{For each without_helmet}
        H --> I[Find matching person<br/>is_head_inside_person]
        I --> J{Person on vehicle?}
        J -->|IoU check| K[âœ… VIOLATION]
    end

    subgraph "Strategy 2: Fallback"
        D & E --> L[Associate riders<br/>person â†” vehicle]
        L --> M{Has with_helmet<br/>in head region?}
        M -->|No| N[âœ… VIOLATION]
        M -->|Yes| O[Safe]
    end

    K --> P[Calculate confidence]
    N --> P
    P --> Q[Deduplication check]
    Q --> R[Final violation list]
```

#### 4.1.3 Key Functions

**1. Associate Riders (Person â†” Vehicle)**:

```python
def associate_riders(persons: List, bikes: List) -> List[Tuple]:
    """
    LiÃªn káº¿t ngÆ°á»i vá»›i xe Ä‘á»ƒ xÃ¡c Ä‘á»‹nh rider.
    Äiá»u kiá»‡n:
    - Bottom center cá»§a person náº±m trong vehicle box
    - HOáº¶C IoU(person, vehicle) >= 0.15
    Má»—i xe cÃ³ thá»ƒ cÃ³ tá»‘i Ä‘a 3 riders.
    """
```

**2. Head Region Check**:

```python
def is_head_inside_person(head_box, person_box, head_region_ratio=0.5):
    """
    Kiá»ƒm tra head box cÃ³ náº±m trong vÃ¹ng Ä‘áº§u cá»§a person khÃ´ng.
    - Head center x pháº£i náº±m trong person width
    - Head center y pháº£i náº±m trong 50% trÃªn cá»§a person
    """
```

**3. Confidence Calculation**:

```python
CONFIDENCE_WEIGHT_PERSON = 0.25
CONFIDENCE_WEIGHT_VEHICLE = 0.25
CONFIDENCE_WEIGHT_NO_HELMET = 0.50

confidence = (
    person_conf * 0.25 +
    vehicle_conf * 0.25 +
    no_helmet_factor * 0.50
)
# Bonus +0.1 náº¿u Ä‘ang trÃªn xe
```

#### 4.1.4 Violation Deduplicator

TrÃ¡nh trÃ¹ng láº·p khi track ID thay Ä‘á»•i (do occlusion):

```python
class ViolationDeduplicator:
    def __init__(self,
                 time_threshold: float = 3.0,    # Cooldown 3 giÃ¢y
                 distance_threshold: float = 50  # 50 pixels
    ):

    def is_duplicate(self, track_id, person_box, current_time) -> bool:
        """
        Check duplicate báº±ng:
        1. CÃ¹ng track_id trong cooldown
        2. KhÃ¡c track_id nhÆ°ng cÃ¹ng vá»‹ trÃ­ (distance < 50px)
        """
```

### 4.2 PhÃ¡t Hiá»‡n VÆ°á»£t ÄÃ¨n Äá» (`redlight_detector.py`)

#### 4.2.1 Traffic Light Detection

```mermaid
flowchart TD
    A[Frame] --> B{Method 1:<br/>YOLO Detection}
    B -->|Found| C[Crop traffic light]
    B -->|Not found| D{Method 2:<br/>ROI Fallback}
    D --> E[Crop from config ROI]
    C --> F[HSV Color Analysis]
    E --> F

    F --> G[Red mask 1: H=0-10]
    F --> H[Red mask 2: H=160-180]
    F --> I[Green mask: H=40-80]
    F --> J[Yellow mask: H=20-35]

    G & H --> K[Red pixels count]
    I --> L[Green pixels count]
    J --> M[Yellow pixels count]

    K & L & M --> N{Compare counts}
    N -->|Red > 50 & max| O[RED]
    N -->|Green > 50 & max| P[GREEN]
    N -->|Yellow > 50| Q[YELLOW]
    N -->|else| R[UNKNOWN]
```

**HSV Color Ranges**:

```python
DEFAULT_COLOR_CONFIG = {
    "red_lower1": [0, 100, 100],      # Äá» (lower spectrum)
    "red_upper1": [10, 255, 255],
    "red_lower2": [160, 100, 100],    # Äá» (upper spectrum)
    "red_upper2": [180, 255, 255],
    "green_lower": [40, 100, 100],
    "green_upper": [80, 255, 255],
    "yellow_lower": [20, 100, 100],
    "yellow_upper": [35, 255, 255]
}
```

#### 4.2.2 Violation Detection Logic

```python
class RedLightViolationChecker:
    def check_violation(self, track_info, light_state) -> bool:
        # Chá»‰ check khi Ä‘Ã¨n Ä‘á»
        if light_state != "RED":
            return False

        # Láº¥y Ä‘iá»ƒm Ä‘Ã¡y giá»¯a cá»§a vehicle
        _, vehicle_y = bottom_center(track_info["box"])

        # Check theo hÆ°á»›ng vi pháº¡m (above/below)
        if self.violation_direction == "above":
            crossed_now = vehicle_y < self.stop_line_y
        else:
            crossed_now = vehicle_y > self.stop_line_y

        # Vi pháº¡m = vá»«a vÆ°á»£t line (khÃ´ng pháº£i Ä‘Ã£ á»Ÿ bÃªn kia tá»« trÆ°á»›c)
        if crossed_now and not track_info.get("crossed", False):
            track_info["crossed"] = True
            return True

        return False
```

> **Quan trá»ng**: Há»‡ thá»‘ng há»— trá»£ 2 hÆ°á»›ng vi pháº¡m:
>
> - `"above"`: Vi pháº¡m khi xe di chuyá»ƒn tá»« dÆ°á»›i lÃªn trÃªn stop line
> - `"below"`: Vi pháº¡m khi xe di chuyá»ƒn tá»« trÃªn xuá»‘ng dÆ°á»›i stop line

### 4.3 PhÃ¡t Hiá»‡n Láº¥n LÃ n (`lane_detector.py`)

#### 4.3.1 Lane Line Representation

```python
class LaneLine:
    def __init__(self, line_config, line_id):
        self.id = line_id
        self.x1, self.y1 = line_config["x1"], line_config["y1"]
        self.x2, self.y2 = line_config["x2"], line_config["y2"]
        self.line_type = line_config.get("type", "solid")  # solid/dashed
```

#### 4.3.2 Point-to-Line Side Calculation

CÃ´ng thá»©c xÃ¡c Ä‘á»‹nh Ä‘iá»ƒm náº±m bÃªn nÃ o cá»§a Ä‘Æ°á»ng tháº³ng:

$$d = (x_2 - x_1)(p_y - y_1) - (y_2 - y_1)(p_x - x_1)$$

- $d > 0$: Äiá»ƒm náº±m bÃªn pháº£i
- $d < 0$: Äiá»ƒm náº±m bÃªn trÃ¡i
- $d = 0$: Äiá»ƒm náº±m trÃªn Ä‘Æ°á»ng

```python
def get_line_side(px, py, x1, y1, x2, y2) -> int:
    """Returns: -1 (left), 0 (on line), 1 (right)"""
    d = (x2 - x1) * (py - y1) - (y2 - y1) * (px - x1)
    return 1 if d > 0 else (-1 if d < 0 else 0)
```

#### 4.3.3 Violation Detection

```mermaid
flowchart TD
    A[Vehicle detected] --> B[Get bottom center]
    B --> C[For each solid line]
    C --> D[Get current side]
    D --> E{First time?}
    E -->|Yes| F[Record initial side]
    E -->|No| G{Side changed?}
    G -->|No| H[Continue tracking]
    G -->|Yes| I{Previous â‰  0<br/>Current â‰  0?}
    I -->|Yes| J{Distance < 2Ã—threshold?}
    J -->|Yes| K[âš ï¸ LANE VIOLATION]
    J -->|No| H
    I -->|No| H
```

```python
class LaneViolationChecker:
    def check_violation(self, track_id, track_info) -> Optional[Dict]:
        # Láº¥y Ä‘iá»ƒm Ä‘Ã¡y giá»¯a cá»§a xe
        px, py = bottom_center(track_info["box"])

        for line in self.lane_lines:
            if not line.is_solid():
                continue  # Chá»‰ check solid line

            current_side = line.get_side(px, py)
            previous_side = self.vehicle_line_sides[track_id].get(line.id, 0)

            # Vi pháº¡m = thay Ä‘á»•i side (khÃ´ng qua 0)
            if previous_side != 0 and current_side != 0:
                if previous_side != current_side:
                    return {
                        "type": "solid_line_crossing",
                        "line_id": line.id,
                        "from_side": "left" if previous_side == -1 else "right",
                        "to_side": "left" if current_side == -1 else "right"
                    }

        return None
```

---

## 5. Object Tracking

### 5.1 CentroidTracker (`pipeline/detectors/tracker.py`)

Thuáº­t toÃ¡n tracking Ä‘Æ¡n giáº£n dá»±a trÃªn khoáº£ng cÃ¡ch centroid:

```python
class CentroidTracker:
    def __init__(self, max_dist=100, ttl_sec=2.0):
        """
        Args:
            max_dist: Khoáº£ng cÃ¡ch tá»‘i Ä‘a (pixels) Ä‘á»ƒ match track
            ttl_sec: Thá»i gian sá»‘ng cá»§a track khi khÃ´ng detect Ä‘Æ°á»£c
        """
        self.tracks = {}  # track_id -> track_info
        self.next_id = 1
```

### 5.2 Thuáº­t ToÃ¡n Matching

```mermaid
flowchart LR
    subgraph "Frame N"
        D1[Detection 1]
        D2[Detection 2]
    end

    subgraph "Existing Tracks"
        T1[Track ID=1<br/>Centroid: 100,200]
        T2[Track ID=2<br/>Centroid: 300,400]
    end

    subgraph "Frame N+1"
        D3[Detection A<br/>Centroid: 105,205]
        D4[Detection B<br/>Centroid: 310,405]
    end

    T1 -.->|"d=7.07px < 100"| D3
    T2 -.->|"d=11.18px < 100"| D4

    D3 -->|Matched| T1_new[Update Track 1]
    D4 -->|Matched| T2_new[Update Track 2]
```

**Quy trÃ¬nh**:

1. Loáº¡i bá» tracks quÃ¡ TTL (2 giÃ¢y khÃ´ng detect)
2. Vá»›i má»—i detection má»›i, tÃ­nh Euclidean distance Ä‘áº¿n táº¥t cáº£ existing tracks
3. Match vá»›i track gáº§n nháº¥t náº¿u distance < max_dist (100px)
4. Náº¿u khÃ´ng match Ä‘Æ°á»£c, táº¡o track má»›i

```python
def update(self, detections, now_ts) -> Dict:
    # 1. Cleanup stale tracks
    for tid in list(self.tracks.keys()):
        if (now_ts - self.tracks[tid]["t"]) > self.ttl_sec:
            del self.tracks[tid]

    # 2. Greedy assignment
    for box, extra_info in detections:
        cx, cy = centroid(box)

        # Find nearest track
        best_id, best_dist = None, float('inf')
        for tid, tr in self.tracks.items():
            d = sqrt((cx - tr["c"][0])**2 + (cy - tr["c"][1])**2)
            if d < best_dist:
                best_dist = d
                best_id = tid

        if best_id and best_dist <= self.max_dist:
            # Update existing track
            self.tracks[best_id]["c"] = (cx, cy)
            self.tracks[best_id]["t"] = now_ts
        else:
            # Create new track
            self.tracks[self.next_id] = {
                "c": (cx, cy), "t": now_ts, "box": box, "crossed": False
            }
            self.next_id += 1
```

---

## 6. Data Pipeline

### 6.1 Kafka Topics

| Topic                 | Producer                   | Consumer      | MÃ´ táº£                      |
| --------------------- | -------------------------- | ------------- | -------------------------- |
| `helmet_video_frames` | video_producer.py          | All consumers | Raw video frames (base64)  |
| `helmet_violations`   | helmet_detector_consumer   | backend       | Helmet violations          |
| `redlight_violations` | redlight_detector_consumer | backend       | Red light violations       |
| `lane_violations`     | lane_detector_consumer     | backend       | Lane violations            |
| `traffic_violations`  | spark_processor            | backend       | General traffic violations |

### 6.2 Message Format

**Input Frame Message**:

```json
{
  "camera_id": "cam1",
  "frame_number": 1234,
  "timestamp": "2025-01-14T15:30:00.000Z",
  "image_base64": "base64_encoded_jpeg",
  "width": 1920,
  "height": 1080
}
```

**Violation Output Message**:

```json
{
  "violation_id": "uuid-string",
  "timestamp": "2025-01-14T15:30:01.000Z",
  "camera_id": "cam1",
  "violation_type": "RED_LIGHT",
  "vehicle_type": "car",
  "traffic_light_state": "RED",
  "confidence": 0.92,
  "track_id": 5,
  "frame_number": 1234,
  "bounding_box": { "x": 100, "y": 200, "w": 150, "h": 100 },
  "image_path": "/app/violations/redlight/redlight_cam1_20250114_153001_uuid.jpg",
  "image_base64": "base64_encoded_annotated_image",
  "metadata": {
    "stop_line_y": 840,
    "violation_direction": "above",
    "frame_size": [1920, 1080]
  }
}
```

### 6.3 Consumer Workflow

```mermaid
sequenceDiagram
    participant P as Video Producer
    participant K as Kafka
    participant C as Detector Consumer
    participant D as Detection Logic
    participant DB as PostgreSQL
    participant BE as Backend
    participant FE as Frontend

    P->>K: Send frame (base64)
    K->>C: Consume frame
    C->>D: Process detection
    D->>D: YOLO inference
    D->>D: Apply violation logic
    D->>D: Track objects

    alt Violation detected
        D->>C: Return violations
        C->>C: Save annotated image
        C->>K: Send violation message
        K->>BE: Consume violation
        BE->>DB: Insert record
        BE->>FE: WebSocket broadcast
    end
```

---

## 7. CÆ¡ Sá»Ÿ Dá»¯ Liá»‡u

### 7.1 Schema Design

**Helmet Violations Table**:

```sql
CREATE TABLE helmet_violations (
    id SERIAL PRIMARY KEY,
    violation_id VARCHAR(255) UNIQUE NOT NULL,
    timestamp TIMESTAMP NOT NULL,
    camera_id VARCHAR(100),
    track_id INTEGER,
    frame_number INTEGER,
    confidence FLOAT,
    bbox_x INTEGER,
    bbox_y INTEGER,
    bbox_w INTEGER,
    bbox_h INTEGER,
    image_path VARCHAR(500),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_helmet_camera ON helmet_violations(camera_id);
CREATE INDEX idx_helmet_timestamp ON helmet_violations(timestamp);
```

**Red Light Violations Table**:

```sql
CREATE TABLE redlight_violations (
    id SERIAL PRIMARY KEY,
    violation_id VARCHAR(255) UNIQUE NOT NULL,
    timestamp TIMESTAMP NOT NULL,
    camera_id VARCHAR(100),
    track_id INTEGER,
    frame_number INTEGER,
    violation_type VARCHAR(50),
    vehicle_type VARCHAR(50),
    traffic_light_state VARCHAR(20),
    confidence FLOAT,
    bbox_x INTEGER,
    bbox_y INTEGER,
    bbox_w INTEGER,
    bbox_h INTEGER,
    image_path VARCHAR(500),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_redlight_camera ON redlight_violations(camera_id);
CREATE INDEX idx_redlight_timestamp ON redlight_violations(timestamp);
CREATE INDEX idx_redlight_vehicle ON redlight_violations(vehicle_type);
```

### 7.2 Database Connection

```python
# apps/backend/main.py
DB_HOST = os.getenv('DB_HOST', 'postgres')
DB_PORT = os.getenv('DB_PORT', '5432')
DB_NAME = os.getenv('DB_NAME', 'traffic_monitoring')
DB_USER = os.getenv('DB_USER', 'airflow')
DB_PASSWORD = os.getenv('DB_PASSWORD', 'airflow')

def get_db_connection():
    return psycopg2.connect(
        host=DB_HOST, port=DB_PORT, dbname=DB_NAME,
        user=DB_USER, password=DB_PASSWORD,
        cursor_factory=RealDictCursor
    )
```

---

## 8. Cáº¥u HÃ¬nh ROI

### 8.1 Cáº¥u TrÃºc Config File (`config/roi_config.json`)

```json
{
  "cam1": {
    "frame_width": 1920,
    "frame_height": 1080,
    "stop_line": {
      "y": 646,
      "tolerance": 30,
      "violation_direction": "above"
    },
    "traffic_light_roi": {
      "x1": 28,
      "y1": 9,
      "x2": 184,
      "y2": 190
    },
    "detection_zone": [
      [640, 406],
      [1167, 410],
      [1899, 1014],
      [52, 1018]
    ],
    "color_detection": {
      "red_lower1": [0, 100, 100],
      "red_upper1": [10, 255, 255],
      "red_lower2": [160, 100, 100],
      "red_upper2": [180, 255, 255],
      "green_lower": [40, 100, 100],
      "green_upper": [80, 255, 255],
      "yellow_lower": [20, 100, 100],
      "yellow_upper": [35, 255, 255]
    },
    "lane_lines": [
      { "x1": 640, "y1": 406, "x2": 52, "y2": 1018, "type": "solid" },
      { "x1": 900, "y1": 408, "x2": 950, "y2": 1016, "type": "dashed" },
      { "x1": 1167, "y1": 410, "x2": 1899, "y2": 1014, "type": "solid" }
    ],
    "lane_crossing_threshold": 40
  }
}
```

### 8.2 Config Parameters

| Parameter                       | Type   | MÃ´ táº£                                   |
| ------------------------------- | ------ | --------------------------------------- |
| `frame_width/height`            | int    | KÃ­ch thÆ°á»›c frame chuáº©n Ä‘á»ƒ scale config  |
| `stop_line.y`                   | int    | Vá»‹ trÃ­ Y cá»§a váº¡ch dá»«ng                  |
| `stop_line.tolerance`           | int    | Dung sai (pixels)                       |
| `stop_line.violation_direction` | string | "above" hoáº·c "below"                    |
| `traffic_light_roi`             | object | VÃ¹ng chá»©a Ä‘Ã¨n giao thÃ´ng                |
| `detection_zone`                | array  | Polygon vÃ¹ng detect (lá»c xe ngoÃ i vÃ¹ng) |
| `color_detection`               | object | HSV ranges cho traffic light colors     |
| `lane_lines`                    | array  | Danh sÃ¡ch váº¡ch káº» lÃ n                   |
| `lane_crossing_threshold`       | int    | NgÆ°á»¡ng khoáº£ng cÃ¡ch cho lane violation   |

### 8.3 Scaling Logic

```python
def scale_config(config, actual_width, actual_height):
    """
    Tá»± Ä‘á»™ng scale tá»a Ä‘á»™ tá»« config resolution
    sang actual frame resolution.
    """
    scale_x = actual_width / config.get("frame_width", 1920)
    scale_y = actual_height / config.get("frame_height", 1080)

    scaled_config = {
        "stop_line": {
            "y": int(config["stop_line"]["y"] * scale_y),
            "tolerance": config["stop_line"]["tolerance"],
            "violation_direction": config["stop_line"]["violation_direction"]
        },
        "traffic_light_roi": {
            "x1": int(roi["x1"] * scale_x),
            "y1": int(roi["y1"] * scale_y),
            "x2": int(roi["x2"] * scale_x),
            "y2": int(roi["y2"] * scale_y)
        },
        "detection_zone": [
            [int(pt[0] * scale_x), int(pt[1] * scale_y)]
            for pt in config["detection_zone"]
        ]
    }
    return scaled_config
```

---

## 9. Web Application

### 9.1 Backend API (`apps/backend/main.py`)

#### 9.1.1 REST Endpoints

| Method | Endpoint                   | MÃ´ táº£                               |
| ------ | -------------------------- | ----------------------------------- |
| GET    | `/`                        | Health check                        |
| GET    | `/api/violations`          | Paginated helmet violations         |
| GET    | `/api/violations/latest`   | Latest violations (in-memory cache) |
| GET    | `/api/violations/{id}`     | Get specific violation              |
| GET    | `/api/stats`               | Violation statistics                |
| GET    | `/api/redlight-violations` | Paginated red light violations      |
| GET    | `/api/redlight-stats`      | Red light statistics                |
| GET    | `/api/cameras`             | Active cameras list                 |
| GET    | `/api/videos`              | Available video files               |

#### 9.1.2 WebSocket Endpoints

| Endpoint     | MÃ´ táº£                       |
| ------------ | --------------------------- |
| `/ws`        | Real-time violation updates |
| `/ws/camera` | Live camera video stream    |

#### 9.1.3 WebSocket Flow

```python
# Connection Manager
class ConnectionManager:
    active_connections: List[WebSocket] = []

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

# Kafka Consumer -> WebSocket broadcast
def kafka_consumer_thread():
    for message in consumer:
        violation = message.value
        save_violation_to_db(violation)
        asyncio.run(manager.broadcast(json.dumps(violation)))
```

### 9.2 Frontend Components

| Component         | Chá»©c nÄƒng                    |
| ----------------- | ---------------------------- |
| `CameraViewer`    | Multi-camera live view       |
| `StatsCard`       | Statistics display cards     |
| `ViolationCard`   | Violation display with image |
| `VideoSourceList` | Available video sources      |

---

## 10. Hiá»‡u Suáº¥t vÃ  ÄÃ¡nh GiÃ¡

### 10.1 Performance Metrics

| ThÃ nh pháº§n         | Metric         | GiÃ¡ trá»‹                  |
| ------------------ | -------------- | ------------------------ |
| Video Producer     | Throughput     | 15 FPS Ã— N videos        |
| YOLO Inference     | Speed (CPU)    | ~30 FPS                  |
| YOLO Inference     | Speed (GPU)    | ~100+ FPS                |
| End-to-End Latency | Total          | < 500ms                  |
| Kafka              | Message size   | ~100-500KB (with base64) |
| WebSocket          | Update latency | < 100ms                  |

### 10.2 Detection Accuracy

| Vi pháº¡m   | Metric    | GiÃ¡ trá»‹ |
| --------- | --------- | ------- |
| Helmet    | mAP@0.5   | ~85%    |
| Red Light | Precision | ~90%    |
| Lane      | Accuracy  | ~80%    |

### 10.3 Resource Usage

| Resource | Estimated Usage       |
| -------- | --------------------- |
| RAM      | 6-8 GB (full stack)   |
| CPU      | 4+ cores recommended  |
| Disk     | 10+ GB for violations |
| Network  | ~10 Mbps per camera   |

---

## 11. Háº¡n Cháº¿ vÃ  HÆ°á»›ng PhÃ¡t Triá»ƒn

### 11.1 Háº¡n Cháº¿ Hiá»‡n Táº¡i

1. **GÃ³c camera cá»‘ Ä‘á»‹nh**: Cáº§n cáº¥u hÃ¬nh ROI thá»§ cÃ´ng cho má»—i camera
2. **KhÃ´ng nháº­n dáº¡ng biá»ƒn sá»‘**: ChÆ°a cÃ³ OCR integration
3. **Single-node processing**: ChÆ°a há»— trá»£ distributed processing
4. **GPU acceleration**: ChÆ°a optimize cho TensorRT

### 11.2 HÆ°á»›ng PhÃ¡t Triá»ƒn

#### Phase 1: Enhanced Detection

- [ ] OCR nháº­n dáº¡ng biá»ƒn sá»‘ xe
- [ ] Æ¯á»›c lÆ°á»£ng tá»‘c Ä‘á»™ xe
- [ ] GPU acceleration vá»›i TensorRT/ONNX
- [ ] Wrong-way driving detection

#### Phase 2: Scalability

- [ ] Multi-worker Spark cluster
- [ ] Kafka partitioning theo camera
- [ ] Redis caching cho API
- [ ] Load balancer for backend

#### Phase 3: Integration

- [ ] Email/SMS alerts
- [ ] Mobile app (React Native)
- [ ] Admin panel configuration UI
- [ ] Export reports (PDF/Excel)
- [ ] Integration vá»›i há»‡ thá»‘ng xá»­ pháº¡t

---

## Phá»¥ Lá»¥c

### A. CÃ´ng Thá»©c ToÃ¡n Há»c

**1. Intersection over Union (IoU)**:
$$IoU = \frac{|A \cap B|}{|A \cup B|} = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}$$

**2. Euclidean Distance (Tracking)**:
$$d = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$$

**3. Point-to-Line Distance**:
$$d = \frac{|(x_2-x_1)(y_1-y_p) - (x_1-x_p)(y_2-y_1)|}{\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}}$$

**4. Confidence Score (Helmet)**:
$$C = 0.25 \cdot C_{person} + 0.25 \cdot C_{vehicle} + 0.50 \cdot C_{no\_helmet}$$

### B. Tech Stack Summary

| Layer         | Technology           | Version  |
| ------------- | -------------------- | -------- |
| AI Model      | YOLOv8 (Ultralytics) | 8.x      |
| Message Queue | Apache Kafka         | 7.5.0    |
| Orchestration | Apache Airflow       | 2.9.0    |
| Database      | PostgreSQL           | 13       |
| Cache/Broker  | Redis                | 8.2.2    |
| Backend       | FastAPI              | Latest   |
| Frontend      | Next.js              | 16.x     |
| Language      | Python               | 3.9/3.12 |
| Runtime       | Node.js              | 22       |
| Container     | Docker Compose       | Latest   |

